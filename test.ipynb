{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOFVaQQ0Zqko"
      },
      "source": [
        "# Test NERDA with Google Colab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/smaakage85/nerda-colab/blob/main/test.ipynb)\n",
        "\n",
        "**Make sure that Google Colab Runtime is set to GPU**.\n",
        "\n",
        "Install NERDA. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J64Twp-yaFVb",
        "outputId": "995c5cdc-6ed6-4532-a51d-0de17127e0a8"
      },
      "source": [
        "!pip install NERDA"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting NERDA\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/93/c0b71e6473181bf16c820cf38a997525dacd40a55d749ac5db7f73fe6781/NERDA-0.8.6-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from NERDA) (1.7.0+cu101)\n",
            "Collecting progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from NERDA) (0.0)\n",
            "Collecting transformers<=3.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from NERDA) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from NERDA) (1.1.5)\n",
            "Collecting pyconll\n",
            "  Downloading https://files.pythonhosted.org/packages/39/6f/86bd5d0eaa6821ba9193bbed16b660ea6f342fe63ec2e4fa2c61377bb44b/pyconll-2.3.3-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->NERDA) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->NERDA) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->NERDA) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->NERDA) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->NERDA) (0.22.2.post1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1->NERDA) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1->NERDA) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 33.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1->NERDA) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1->NERDA) (2019.12.20)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1->NERDA) (20.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1->NERDA) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->NERDA) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->NERDA) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->NERDA) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->NERDA) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->NERDA) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1->NERDA) (51.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1->NERDA) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1->NERDA) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1->NERDA) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1->NERDA) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<=3.5.1->NERDA) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<=3.5.1->NERDA) (2.4.7)\n",
            "Building wheels for collected packages: progressbar, sacremoses\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12075 sha256=9e661a371907dc4e93feaf4fd54f2cec9be11514e0449c32e8324a9bfac211b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=646a7a6ec0e21cde0512606f8784a40d5427744111c545f2cb815d5da430617d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built progressbar sacremoses\n",
            "Installing collected packages: progressbar, sentencepiece, tokenizers, sacremoses, transformers, pyconll, NERDA\n",
            "Successfully installed NERDA-0.8.6 progressbar-2.5 pyconll-2.3.3 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJXDIRBXaamM"
      },
      "source": [
        "Import dependencies and download ressources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "HdlGPT1RakMg",
        "outputId": "9fdedfa7-0e18-4f82-d92c-ef69d3442dc2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from NERDA.datasets import download_dane_data, get_dane_data\n",
        "from NERDA.models import NERDA\n",
        "# download Danish NER data set, DaNE\n",
        "download_dane_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Reading http://danlp-downloads.alexandra.dk/datasets/ddt.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'archive extracted to /root/.dane'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crlwq0Q2ayc3"
      },
      "source": [
        "## Train ELECTRA model for NER in Danish\n",
        "\n",
        "Set model configuration. Remember to set Google Colab Runtime to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBQjxMZdc0-8",
        "outputId": "fadf9117-83f3-4bce-bb9a-39f127526f32"
      },
      "source": [
        "tag_scheme = ['B-PER',\n",
        "              'I-PER', \n",
        "              'B-ORG', \n",
        "              'I-ORG', \n",
        "              'B-LOC', \n",
        "              'I-LOC', \n",
        "              'B-MISC', \n",
        "              'I-MISC']\n",
        "model = NERDA(dataset_training = get_dane_data('train'),\n",
        "              dataset_validation = get_dane_data('dev'),\n",
        "              tag_scheme = tag_scheme,\n",
        "              tag_outside = 'O',\n",
        "              transformer = 'Maltehb/-l-ctra-danish-electra-small-uncased',\n",
        "              hyperparameters = {'epochs' : 5,\n",
        "                                 'warmup_steps' : 500,\n",
        "                                 'train_batch_size': 13,\n",
        "                                 'learning_rate': 0.0001})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device automatically set to: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ifneZ8edL1o"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "U5-QJhKhdQFN",
        "outputId": "25c6d70d-f08b-4901-d218-ce66551abf0c"
      },
      "source": [
        "model.train()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/338 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 274/338 [00:23<00:05, 11.42it/s]/usr/local/lib/python3.6/dist-packages/NERDA/preprocessing.py:75: UserWarning: Sentence #3595 length 160 exceeds max_len 128 and has been truncated\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 338/338 [00:28<00:00, 11.89it/s]\n",
            "100%|██████████| 71/71 [00:02<00:00, 35.19it/s]\n",
            "  0%|          | 0/338 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.6901343162639959 Valid Loss = 0.2215158384240849\n",
            "\n",
            " Epoch 2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 273/338 [00:22<00:05, 11.95it/s]/usr/local/lib/python3.6/dist-packages/NERDA/preprocessing.py:75: UserWarning: Sentence #3595 length 160 exceeds max_len 128 and has been truncated\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 338/338 [00:28<00:00, 11.79it/s]\n",
            "100%|██████████| 71/71 [00:02<00:00, 32.00it/s]\n",
            "  0%|          | 0/338 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.18718081671391895 Valid Loss = 0.14077660121338467\n",
            "\n",
            " Epoch 3 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 273/338 [00:22<00:05, 11.84it/s]/usr/local/lib/python3.6/dist-packages/NERDA/preprocessing.py:75: UserWarning: Sentence #3595 length 160 exceeds max_len 128 and has been truncated\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 338/338 [00:28<00:00, 12.00it/s]\n",
            "100%|██████████| 71/71 [00:02<00:00, 32.09it/s]\n",
            "  0%|          | 0/338 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.10380902324290671 Valid Loss = 0.12002295927262642\n",
            "\n",
            " Epoch 4 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 274/338 [00:23<00:05, 12.42it/s]/usr/local/lib/python3.6/dist-packages/NERDA/preprocessing.py:75: UserWarning: Sentence #3595 length 160 exceeds max_len 128 and has been truncated\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 338/338 [00:29<00:00, 11.59it/s]\n",
            "100%|██████████| 71/71 [00:02<00:00, 32.31it/s]\n",
            "  0%|          | 0/338 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.06557886774056541 Valid Loss = 0.10949709867192826\n",
            "\n",
            " Epoch 5 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 274/338 [00:23<00:05, 11.77it/s]/usr/local/lib/python3.6/dist-packages/NERDA/preprocessing.py:75: UserWarning: Sentence #3595 length 160 exceeds max_len 128 and has been truncated\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 338/338 [00:28<00:00, 11.81it/s]\n",
            "100%|██████████| 71/71 [00:01<00:00, 36.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.04763972320312843 Valid Loss = 0.11310201950213859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Model trained successfully'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPZEx_ORdWDi"
      },
      "source": [
        "Evaluate performance of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "JptSJ9HkdX4S",
        "outputId": "079659ca-ab25-4562-8cd8-26fa602d8b01"
      },
      "source": [
        "model.evaluate_performance(get_dane_data('test'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Level</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-PER</td>\n",
              "      <td>0.918033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I-PER</td>\n",
              "      <td>0.974729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-ORG</td>\n",
              "      <td>0.662069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I-ORG</td>\n",
              "      <td>0.722689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-LOC</td>\n",
              "      <td>0.779817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I-LOC</td>\n",
              "      <td>0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B-MISC</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I-MISC</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVG_MICRO</td>\n",
              "      <td>0.798246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVG_MACRO</td>\n",
              "      <td>0.757267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Level  F1-Score\n",
              "0      B-PER  0.918033\n",
              "1      I-PER  0.974729\n",
              "2      B-ORG  0.662069\n",
              "3      I-ORG  0.722689\n",
              "4      B-LOC  0.779817\n",
              "5      I-LOC  0.615385\n",
              "6     B-MISC  0.666667\n",
              "7     I-MISC  0.718750\n",
              "0  AVG_MICRO  0.798246\n",
              "0  AVG_MACRO  0.757267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-u_HAIadj52"
      },
      "source": [
        "Predict new text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXN_iXsado-k",
        "outputId": "b7cda766-787d-4164-8ca6-07e76a63a549"
      },
      "source": [
        "text = \"Cristiano Ronaldo spiller for Juventus FC\" \n",
        "model.predict_text(text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['Cristiano', 'Ronaldo', 'spiller', 'for', 'Juventus', 'FC']],\n",
              " [['B-PER', 'I-PER', 'O', 'O', 'B-ORG', 'I-ORG']])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}